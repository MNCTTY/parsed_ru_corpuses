{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for line in open('lighttag_annotations2.json', 'r', encoding='utf-8'):\n",
    "    raw_data.append(json.loads(line))\n",
    "    annotations_and_examples = []\n",
    "    relations = []\n",
    "    #у нас json в одну линию записан, поэтому по сути annannotations_and_examples и relations не обнуляются, и накапливают всю\n",
    "    #инфу, которую надо\n",
    "    for d in raw_data:\n",
    "        for k, v in d.items():\n",
    "            if k == 'annotations_and_examples':\n",
    "                annotations_and_examples.append(v)\n",
    "            if k == 'relations':\n",
    "                relations.append(v)\n",
    "                \n",
    "#we have no relations in our task, so we need not them to append, so we need not the_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotations_and_examples contains:\n",
    "\n",
    "# content\n",
    "# metadata\n",
    "# annotations \n",
    "# classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for line in annotations_and_examples[0]:\n",
    "    raw_data.append((line))\n",
    "    content = []\n",
    "    metadata = []\n",
    "    annotations = []\n",
    "    classifications = []\n",
    "    for d in raw_data:\n",
    "        for k, v in d.items():\n",
    "            if k == 'content':\n",
    "                content.append(v)\n",
    "            if k == 'metadata':\n",
    "                metadata.append(v)\n",
    "            if k == 'annotations':\n",
    "                annotations.append(v)\n",
    "            if k == 'classifications':\n",
    "                classifications.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for line in annotations[0]:\n",
    "    raw_data.append((line))\n",
    "    starts = []\n",
    "    ends = []\n",
    "    tags = []\n",
    "    for d in raw_data:\n",
    "        for k, v in d.items():\n",
    "            if k == 'start':\n",
    "                starts.append(v)\n",
    "            if k == 'end':\n",
    "                ends.append(v)\n",
    "            if k == 'tag':\n",
    "                tags.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_content = content.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_content) == len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_content = list(tagged_content[0])\n",
    "\n",
    "for i in range(0, len(list_content)):\n",
    "    if list_content[i] != ' ' and list_content[i] != '#' and list_content[i] != '\\n':\n",
    "        list_content[i] = 'O'\n",
    "        \n",
    "tagged_content[0] = \"\".join(list_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_content) == len(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Избегаем схлопывания многословных тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_content = list(tagged_content[0])\n",
    "\n",
    "for i in range(0, len(tags)):\n",
    "    for j in range(starts[i], ends[i]):\n",
    "        if content[0][j] == ' ':\n",
    "            list_content[j] = ' '\n",
    "        else:\n",
    "            list_content[j] = tags[i]\n",
    "        \n",
    "tagged_content[0] = \"\".join(list_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_content) == len(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_content[0] = re.sub(r'O+', 'O', tagged_content[0])\n",
    "tagged_content[0] = re.sub(r'ж+', 'ж', tagged_content[0])\n",
    "tagged_content[0] = re.sub(r'п+', 'п', tagged_content[0])\n",
    "tagged_content[0] = re.sub(r'д+', 'д', tagged_content[0])\n",
    "tagged_content[0] = re.sub(r'м+', 'м', tagged_content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_content[0].split(' ')) == len(content[0].split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделяем на тексты и теги к текстам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tags = tagged_content[0].split(' \\n#######\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_texts = content[0].split(' \\n#######\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "if len(list_of_texts) < len(list_of_tags):\n",
    "    list_of_tags = list_of_tags[:-1] #пустой элемент убираем\n",
    "    print(len(list_of_texts))\n",
    "    print(len(list_of_tags))\n",
    "    print('\\n')\n",
    "print(len(list_of_texts))\n",
    "print(len(list_of_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_text_tokens = []\n",
    "for i in range(0, len(list_of_texts)):\n",
    "    list_of_text_tokens.append([list_of_texts[i].split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tags_tokens = []\n",
    "for i in range(0, len(list_of_tags)):\n",
    "    list_of_tags_tokens.append([list_of_tags[i].split(' ')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка совпадения количество тегов - токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(list_of_text_tokens)):\n",
    "    if len(list_of_tags_tokens[i][0])!=len(list_of_text_tokens[i][0]):\n",
    "        print('idx ', i)\n",
    "        print(len(list_of_tags_tokens[i][0]))\n",
    "        print(len(list_of_text_tokens[i][0]))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "слово  МП\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  Нижегородпассажиравтотранс\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  Нижегородской\n",
      "тег  м\n",
      "\n",
      "\n",
      "слово  области\n",
      "тег  м\n",
      "\n",
      "\n",
      "слово  России\n",
      "тег  ж\n",
      "\n",
      "\n",
      "слово  МП\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  Нижегородпассажиравтотранс\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  с\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  января\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  2014\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  года\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  по\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  декабрь\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  2015\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  Нижнего\n",
      "тег  м\n",
      "\n",
      "\n",
      "слово  Новгорода\n",
      "тег  м\n",
      "\n",
      "\n",
      "слово  \n",
      "тег  \n",
      "\n",
      "\n",
      "слово  Дмитрий\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  Цыганков\n",
      "тег  п\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#проверяем по-токеново idx-й текст\n",
    "idx = 7\n",
    "for i in range(0, len((list_of_text_tokens[idx][0]))):\n",
    "    if list_of_tags_tokens[idx][0][i] !='O':\n",
    "        print('слово ',list_of_text_tokens[idx][0][i])\n",
    "        print('тег ',list_of_tags_tokens[idx][0][i])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переворачиваем в нормальные теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_of_tags_tokens = []\n",
    "for i in range(0, len(list_of_tags_tokens)):\n",
    "    sublist = []\n",
    "    for j in range(0, len(list_of_tags_tokens[i][0])):\n",
    "        if list_of_tags_tokens[i][0][j] == 'п':\n",
    "            sublist.append('OFF')\n",
    "        elif list_of_tags_tokens[i][0][j] == 'ж':\n",
    "            sublist.append('SUF')\n",
    "        elif list_of_tags_tokens[i][0][j] == 'д':\n",
    "            sublist.append('DAT')\n",
    "        elif list_of_tags_tokens[i][0][j] == 'м':\n",
    "            sublist.append('LOC')\n",
    "        else:\n",
    "            sublist.append('O')\n",
    "    final_list_of_tags_tokens.append(sublist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_list_of_tags_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_list_of_tags_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_tags_tokens[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заносим все в один датафрейм, сохр csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for i in range(0, len(list_of_text_tokens)):\n",
    "    final.append([list_of_text_tokens[i][0], final_list_of_tags_tokens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Федеральное, налоговое, ведомство, США, по, и...</td>\n",
       "      <td>[O, O, O, SUF, O, O, O, O, O, O, OFF, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Приволжское, следственное, управление, на, тр...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Уголовное, дело, ,, фигурантом, которого, был...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, OFF, OFF, OFF, OFF, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Московская, налоговая, инспекция, проводит, н...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, OFF, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Российское, следствие, объявило, украинского,...</td>\n",
       "      <td>[O, O, O, O, O, OFF, OFF, O, O, O, O, O, SUF, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [Федеральное, налоговое, ведомство, США, по, и...   \n",
       "1  [Приволжское, следственное, управление, на, тр...   \n",
       "2  [Уголовное, дело, ,, фигурантом, которого, был...   \n",
       "3  [Московская, налоговая, инспекция, проводит, н...   \n",
       "4  [Российское, следствие, объявило, украинского,...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [O, O, O, SUF, O, O, O, O, O, O, OFF, O, O, O,...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, OFF, OFF, OFF, OFF, O...  \n",
       "3  [O, O, O, O, O, O, O, O, O, OFF, O, O, O, O, O...  \n",
       "4  [O, O, O, O, O, OFF, OFF, O, O, O, O, O, SUF, ...  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(final, columns=['text', 'tokens'])\n",
    "df.head()\n",
    "#сейчас тут списки токенов, можно потом все завернуть в строку через пробелы, должно сразу все быть хорошо (без добавления/убирания лишних символов и артефактов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Lighttag_parsed_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
