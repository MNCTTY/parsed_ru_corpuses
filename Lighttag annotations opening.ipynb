{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ THE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for line in open('lighttag_annotations_100.json', 'r', encoding='utf-8'):\n",
    "    raw_data.append(json.loads(line))\n",
    "    annotations_and_examples = []\n",
    "    relations = []\n",
    "    #у нас джейсон в одну линию записан, поэтому по сути annannotations_and_examples и relations не обнуляются, и накапливают всю\n",
    "    #инфу, которую надо\n",
    "    for d in raw_data:\n",
    "        for k, v in d.items():\n",
    "            if k == 'annotations_and_examples':\n",
    "                annotations_and_examples.append(v)\n",
    "            if k == 'relations':\n",
    "                relations.append(v)\n",
    "                \n",
    "#we have no relations in our task, so we need not them to append, so we need not the_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotations_and_examples contains:\n",
    "\n",
    "# content\n",
    "# metadata\n",
    "# annotations \n",
    "# classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for line in annotations_and_examples[0]:\n",
    "    raw_data.append((line))\n",
    "    content = []\n",
    "    metadata = []\n",
    "    annotations = []\n",
    "    classifications = []\n",
    "    for d in raw_data:\n",
    "        for k, v in d.items():\n",
    "            if k == 'content':\n",
    "                content.append(v)\n",
    "            if k == 'metadata':\n",
    "                metadata.append(v)\n",
    "            if k == 'annotations':\n",
    "                annotations.append(v)\n",
    "            if k == 'classifications':\n",
    "                classifications.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 1942, 'end': 2003, 'tag': 'п'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[0][186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 348, 'end': 363, 'tag': 'п'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts = []\n",
    "ends = []\n",
    "tags = []\n",
    "\n",
    "for i in range(len(annotations)):\n",
    "    raw_data = []\n",
    "    for line in annotations[i]:\n",
    "        raw_data.append((line))\n",
    "        st = []\n",
    "        en = []\n",
    "        tg = []\n",
    "        for d in raw_data:\n",
    "            for k, v in d.items():\n",
    "                if k == 'start':\n",
    "                    st.append(v)\n",
    "                if k == 'end':\n",
    "                    en.append(v)\n",
    "                if k == 'tag':\n",
    "                    tg.append(v)\n",
    "    starts.append(st)\n",
    "    ends.append(en)\n",
    "    tags.append(tg)\n",
    "\n",
    "len(starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(starts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Янукович '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[1][starts[1][15]:ends[1][15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  пустышка, заполняем нулями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_content = copy.copy(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_content) == len(content), '\\n')\n",
    "\n",
    "for i in range(0, len(content)):\n",
    "    print(len(tagged_content[i])==len(content[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0, len(tagged_content)):\n",
    "    list_content = list(tagged_content[j])\n",
    "\n",
    "    for i in range(0, len(list_content)):\n",
    "        if list_content[i] != ' ' and list_content[i] != '#' and list_content[i] != '\\n':\n",
    "            list_content[i] = 'O'\n",
    "\n",
    "    tagged_content[j] = \"\".join(list_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_content) == len(content), '\\n')\n",
    "\n",
    "for i in range(0, len(content)):\n",
    "    print(len(tagged_content[i])==len(content[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Избегаем схлопывания многословных тегов: все, что в промежутке тега, заполняем его индикатором, но если этот промежуток совпал с пробелом в оригинальном контенте - тут тоже пробел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in range(0, len(tagged_content)):\n",
    "    list_content = list(tagged_content[q])\n",
    "\n",
    "    for i in range(0, len(tags[q])):\n",
    "        for j in range(starts[q][i], ends[q][i]):\n",
    "            if content[q][j] == ' ':\n",
    "                list_content[j] = ' '\n",
    "            else:\n",
    "                list_content[j] = tags[q][i]\n",
    "\n",
    "    tagged_content[q] = \"\".join(list_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_content) == len(content), '\\n')\n",
    "\n",
    "for i in range(0, len(content)):\n",
    "    print(len(tagged_content[i])==len(content[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## хлопаем получившиеся посхедовательности до одного символа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(tagged_content)):\n",
    "    tagged_content[i] = re.sub(r'O+', 'O', tagged_content[i])\n",
    "    tagged_content[i] = re.sub(r'ж+', 'ж', tagged_content[i])\n",
    "    tagged_content[i] = re.sub(r'п+', 'п', tagged_content[i])\n",
    "    tagged_content[i] = re.sub(r'д+', 'д', tagged_content[i])\n",
    "    tagged_content[i] = re.sub(r'м+', 'м', tagged_content[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "\n",
      "True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(tagged_content)):\n",
    "    bull = (len(tagged_content[i].split(' ')) == len(content[i].split(' ')))\n",
    "    print(bull, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAGS AND TEXT BOTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделяем на тексты и теги к текстам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tags = []\n",
    "sub_list_of_tags = []\n",
    "for i in range(0, len(tagged_content)):\n",
    "    sub_list_of_tags.append(tagged_content[i].split('\\n############\\n'))\n",
    "list_of_tags = sub_list_of_tags[0]+sub_list_of_tags[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_texts = []\n",
    "sub_list_of_texts = []\n",
    "for i in range(0, len(content)):\n",
    "    sub_list_of_texts.append(content[i].split('\\n############\\n'))\n",
    "list_of_texts = sub_list_of_texts[0]+sub_list_of_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_texts))\n",
    "print(len(list_of_tags))\n",
    "#список со всеми текстами и список со всеми текстами тегов, элемент - один текст строкой или один текст тегов строкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_text_tokens = []\n",
    "for i in range(0, len(list_of_texts)):\n",
    "    list_of_text_tokens.append([list_of_texts[i].split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tags_tokens = []\n",
    "for i in range(0, len(list_of_tags)):\n",
    "    list_of_tags_tokens.append([list_of_tags[i].split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в целом те же самые списки, только теперь элемент - список токенов или список тегов (строки разбили на отдельные элементы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка совпадения количество тегов - токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(list_of_text_tokens)):\n",
    "    if len(list_of_tags_tokens[i][0])!=len(list_of_text_tokens[i][0]):\n",
    "        print('idx ', i)\n",
    "        print(len(list_of_tags_tokens[i][0]))\n",
    "        print(len(list_of_text_tokens[i][0]))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка соответствия тегов токенам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "слово  Александр\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  Хорошавин\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  Хорошавин\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  Александр\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  Хорошавин\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  в\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  2011\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  году\n",
      "тег  д\n",
      "\n",
      "\n",
      "слово  Сахалинская\n",
      "тег  ж\n",
      "\n",
      "\n",
      "слово  компания\n",
      "тег  ж\n",
      "\n",
      "\n",
      "слово  Энергострой\n",
      "тег  ж\n",
      "\n",
      "\n",
      "слово  Хорошавин\n",
      "тег  п\n",
      "\n",
      "\n",
      "слово  Хорошавин\n",
      "тег  п\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#проверяем по-токеново idx-й текст\n",
    "idx = 100\n",
    "for i in range(0, len((list_of_text_tokens[idx][0]))):\n",
    "    if list_of_tags_tokens[idx][0][i] !='O':\n",
    "        print('слово ',list_of_text_tokens[idx][0][i])\n",
    "        print('тег ',list_of_tags_tokens[idx][0][i])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переворачиваем в нормальные теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_of_tags_tokens = []\n",
    "for i in range(0, len(list_of_tags_tokens)):\n",
    "    sublist = []\n",
    "    for j in range(0, len(list_of_tags_tokens[i][0])):\n",
    "        if list_of_tags_tokens[i][0][j] == 'п':\n",
    "            sublist.append('OFF')\n",
    "        elif list_of_tags_tokens[i][0][j] == 'ж':\n",
    "            sublist.append('SUF')\n",
    "        elif list_of_tags_tokens[i][0][j] == 'д':\n",
    "            sublist.append('DAT')\n",
    "        elif list_of_tags_tokens[i][0][j] == 'м':\n",
    "            sublist.append('LOC')\n",
    "        else:\n",
    "            sublist.append('O')\n",
    "    final_list_of_tags_tokens.append(sublist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_list_of_tags_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_list_of_tags_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_tags_tokens[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заносим все в один датафрейм, подтягиваем столб с оригинальной датой, сохр csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for i in range(0, len(list_of_text_tokens)):\n",
    "    final.append([list_of_text_tokens[i][0], final_list_of_tags_tokens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O O O O O O O O O O OFF O O O O O O O O DAT DAT DAT DAT DAT O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O OFF O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_final = []\n",
    "for i in range(1, len(final)):\n",
    "    str_text = ' '.join(final[i][0])\n",
    "    str_tags = ' '.join(final[i][1])\n",
    "    str_final.append([str_tags, str_text])\n",
    "str_final[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### удаляем номер текста и его айдишник (и внешние кавычки) - ужасные артефакты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str_final[0][1].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str_final[0][0].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(''.join(str_final[0][1].split(\",\")[1:-1]).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(str_final)):\n",
    "    str_final[i][1] = ','.join(str_final[i][1].split(\",\")[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(str_final)):\n",
    "    str_final[i][1] = str_final[i][1].replace('\"', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## все, датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O OFF O O O O O O O O DAT DA...</td>\n",
       "      <td>Федеральное налоговое ведомство США по итогам ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>Приволжское следственное управление на транспо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O O O O O O O O O OFF OFF OFF O O O O O O O O ...</td>\n",
       "      <td>Уголовное дело , фигурантом которого был генер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O O O O O O O O O OFF O O O O O O O O O O O O ...</td>\n",
       "      <td>Московская налоговая инспекция проводит новую ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O O O O O OFF OFF O O O O O LOC O O O O O O O ...</td>\n",
       "      <td>Российское следствие объявило украинского бизн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0  O O O O O O O O O O OFF O O O O O O O O DAT DA...   \n",
       "1  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "2  O O O O O O O O O OFF OFF OFF O O O O O O O O ...   \n",
       "3  O O O O O O O O O OFF O O O O O O O O O O O O ...   \n",
       "4  O O O O O OFF OFF O O O O O LOC O O O O O O O ...   \n",
       "\n",
       "                                               texts  \n",
       "0  Федеральное налоговое ведомство США по итогам ...  \n",
       "1  Приволжское следственное управление на транспо...  \n",
       "2  Уголовное дело , фигурантом которого был генер...  \n",
       "3  Московская налоговая инспекция проводит новую ...  \n",
       "4  Российское следствие объявило украинского бизн...  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(str_final, columns=['tags', 'texts'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Федеральное налоговое ведомство США по итогам аудита обвинило американскую корпорацию Coca-Cola в неуплате налогов на $3 , 3 млрд с 2007 по 2009 годы , сообщает Bloomberg . Пока ведомство не предложило наложить на гиганта рынка штраф . Компания в свою очередь отвергла обвинения и заявила , что намерена искать справедливости в суде . Мы планируем воспользоваться административными и правовыми средствами , которые необходимы для решения вопроса , — говорится в официальном сообщении Coca-Cola . Пресс-служба корпорации подчеркивает , что в течение почти 30 лет следует одной и той же методологии при определении облагаемой налогами части доходов . ,Компанию Coca-Cola обвинили в неуплате налогов на $3,3 млрд'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['texts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Lighttag_0-100_parsed_data_str.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### проверяем формат строк и все такое при подгрузке сформированного файла обратно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O OFF O O O O O O O O DAT DA...</td>\n",
       "      <td>Федеральное налоговое ведомство США по итогам ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>Приволжское следственное управление на транспо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O O O O O O O O O OFF OFF OFF O O O O O O O O ...</td>\n",
       "      <td>Уголовное дело , фигурантом которого был генер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O O O O O O O O O OFF O O O O O O O O O O O O ...</td>\n",
       "      <td>Московская налоговая инспекция проводит новую ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O O O O O OFF OFF O O O O O LOC O O O O O O O ...</td>\n",
       "      <td>Российское следствие объявило украинского бизн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0  O O O O O O O O O O OFF O O O O O O O O DAT DA...   \n",
       "1  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
       "2  O O O O O O O O O OFF OFF OFF O O O O O O O O ...   \n",
       "3  O O O O O O O O O OFF O O O O O O O O O O O O ...   \n",
       "4  O O O O O OFF OFF O O O O O LOC O O O O O O O ...   \n",
       "\n",
       "                                               texts  \n",
       "0  Федеральное налоговое ведомство США по итогам ...  \n",
       "1  Приволжское следственное управление на транспо...  \n",
       "2  Уголовное дело , фигурантом которого был генер...  \n",
       "3  Московская налоговая инспекция проводит новую ...  \n",
       "4  Российское следствие объявило украинского бизн...  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('Lighttag_0-100_parsed_data_str.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tags = []\n",
    "for i in range(0, len(df1['tags'])):\n",
    "    list_of_tags.append(df1['tags'][i].split(' '))\n",
    "\n",
    "list_of_texts = []\n",
    "for i in range(0, len(df1['texts'])):\n",
    "    list_of_texts.append(df1['texts'][i].split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(list_of_texts)):\n",
    "    if len(list_of_tags[i])!=len(list_of_texts[i]):\n",
    "        print('i: ',i)\n",
    "        print('diff: ',len(list_of_texts[i])- len(list_of_tags[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKING FILES FOR DEEP PAVLOV TRAIN NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('train.txt','w', encoding='utf-8') \n",
    "for i in range(0, int(0.8*len(list_of_texts))):\n",
    "    for j in range(0, len(list_of_texts[i])):\n",
    "        line = list_of_texts[i][j] + '\\t' + list_of_tags[i][j] + '\\n'\n",
    "        file.write(line)\n",
    "#        if list_of_texts[i][j] == '.':\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test.txt','w', encoding='utf-8') \n",
    "for i in range(int(0.8*len(list_of_texts)), int(0.9*len(list_of_texts))):\n",
    "    for j in range(0, len(list_of_texts[i])):\n",
    "        line = list_of_texts[i][j] + '\\t' + list_of_tags[i][j] + '\\n'\n",
    "        file.write(line)\n",
    "#        if list_of_texts[i][j] == '.':\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('valid.txt','w', encoding='utf-8') \n",
    "for i in range(int(0.9*len(list_of_texts)), len(list_of_texts)):\n",
    "    for j in range(0, len(list_of_texts[i])):\n",
    "        line = list_of_texts[i][j] + '\\t' + list_of_tags[i][j] + '\\n'\n",
    "        file.write(line)\n",
    "#        if list_of_texts[i][j] == '.':\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
